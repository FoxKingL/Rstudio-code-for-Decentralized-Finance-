---
title: "DeFi Assignment 4 Part 3:"
subtitle: "Assignment 4 Part 3(Fall 2024)"
author: "Haolin Luo"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    toc: true
    number_sections: true
    df_print: paged
  pdf_document: 
    latex_engine: xelatex
---
```{r setup, include=FALSE}

# Required R package installation; RUN THIS BLOCK BEFORE ATTEMPTING TO KNIT THIS NOTEBOOK!!!
# This section  install packages if they are not already installed. 
# This block will not be shown in the knit file.
knitr::opts_chunk$set(echo = TRUE)

# Set the default CRAN repository
local({r <- getOption("repos")
       r["CRAN"] <- "http://cran.r-project.org" 
       options(repos=r)
})

# Required packages for M20 LIBS analysis
if (!require("rmarkdown")) {
  install.packages("rmarkdown")
  library(rmarkdown)
}
if (!require("tidyverse")) {
  install.packages("tidyverse")
  library(tidyverse)
}
if (!require("stringr")) {
  install.packages("stringr")
  library(stringr)
}

if (!require("ggbiplot")) {
  install.packages("ggbiplot")
  library(ggbiplot)
}

if (!require("pheatmap")) {
  install.packages("pheatmap")
  library(pheatmap)
}
if(!require("randomForest")) {
  install.packages("randomForest")
  library(randomForest)
}
if(!require("caret")) {
  install.packages("caret")
  library(caret)
}
if(!require("survival")){
  install.packages("survival")
  library(survival)
}
if(!require("survminer")){
  install.packages("survminer")
  library(survminer)
}
if(!require("ggplot2")){
  install.packages("ggplot2")
  library(ggplot2)
}

if(!require("kableExtra")){
  install.packages("kableExtra")
  library(kableExtra)
}
if(!require("rpart")){
  install.packages("rpart")
  library(rpart)
}

```

```{r}
# Load a single survival dataset with a specific index and outcome event:
indexEvent = "Borrow/"
outcomeEvent = "Account Liquidated/"

my_survivalData = read_rds(paste0("/academics/MATP-4910-F24/DAR-DeFi-LTM-F24/Data/Survival_Data/", 
                               indexEvent, outcomeEvent, "survivalData.rds"))

# Rescale the timeDiff column to be in Days instead of Seconds
my_survivalData <- my_survivalData %>%
  mutate(timeDiff = timeDiff / 86400)

# Create a Surv object with our survival data:
my_survObj <- Surv(time = my_survivalData$timeDiff, event = my_survivalData$status)

# Fit a KM curve to this data:
my_survFit <- surv_fit(my_survObj ~ 1, data = my_survivalData)

my_survivalData <- my_survivalData %>%
  filter(!(timeDiff >= 69.36 & status == 0)) # filter out censored events with timeDiff less 
                                        # than one day

my_survivalDataForClassification <- my_survivalData %>%
  mutate(event = case_when(timeDiff <= 69.36 ~ "yes", # if the timeDiff is below our threshold, 
                                                  # set event="yes"
                           timeDiff > 69.36 ~ "no"))  # otherwise set event = "no"
# Plot the Kaplan--Meier curve:
my_kmPlot <- ggsurvplot(my_survFit,
             censor = FALSE,
             title = "How much percent of users is liquidated after borrowing money?",
             xlab = "Time (days)",
             break.x.by = 100,
             ylab = "Probability of Get liquidated",
             conf.int = TRUE)

my_kmPlot


# We need to be careful with the features we include. Some of the features present in 
# the data are not meant for performing tasks like classification, like the outcomeTime 
# which is NA for any censored events. Let's drop these features:

featuresToDrop = c("indexTime",   # This feature is primarily present for data exploration 
                                  # and investigation, but could interfere with a 
                                  # proper experiment
                   "outcomeTime", # This features is NA whenever an event is right-censored, 
                                  # which is often.
                   "id",          # This represents the transaction ID of the index event, 
                                  # which is useful for further investigation but not for 
                                  # an experiment
                   "Index Event", # For the sake of this exercise, the index event and outcome 
                                  # event should be the same for every row
                   "Outcome Event",
                   "timeDiff",    # event is based on timeDiff, which is what we're trying to 
                                  # predict for this classification problem
                   "deployment",  # this will be the same for all rows within a single 
                                  # survival dataset
                   "version",     # this will be the same for all rows within a single 
                                  # survival dataset
                   "indexID",     # this is only useful for looking up more details about a 
                                  # single transaction
                   "user",        # the user *could* be useful, but it's difficult to effectively 
                                  # use since its a factor with tons of levels
                   "status",      # this is sort of wrapped up in the "event" column we are trying
                                  # to predict
                   "quarter", 
                   
                   "liquidator"             
                   ) 

my_survivalDataForClassification <- my_survivalDataForClassification %>%
  select(-any_of(featuresToDrop)) %>% # Drop an entire list of named features
  drop_na()

# We also should convert relevant columns to factors:
my_survivalDataForClassification[] <- lapply(my_survivalDataForClassification, 
                                          function(x) if(is.character(x)) as.factor(x) else x)


# Compute the percentage of events in "yes" and "no"
pctPerEvent <- my_survivalDataForClassification %>%
  group_by(event) %>%
  dplyr::summarize(numPerEvent = n()) %>%
  mutate(total = sum(numPerEvent)) %>%
  mutate(percentage = numPerEvent / total) %>%
  dplyr::select(event, percentage)

kable(pctPerEvent) # View these percentages

#clean data
cleaned_data <- na.omit(my_survivalDataForClassification)
# Split data into training and test datasets
set.seed(123) # For reproducibility
# Ensure event column is a factor with exactly two levels
cleaned_data$event <- factor(cleaned_data$event, levels = c("yes", "no"))

# Now, try creating the partition again
set.seed(123)
trainIndex3 <- createDataPartition(cleaned_data$event, p = 0.8, list = FALSE)
#convert some int data into factors
cleaned_data$amountUSDQuartile <- as.factor(cleaned_data$amountUSDQuartile)
cleaned_data$principalAmountUSDQuartile <- as.factor(cleaned_data$principalAmountUSDQuartile)
cleaned_data$amountNativeQuartile <- as.factor(cleaned_data$amountNativeQuartile)
cleaned_data$collateralAmountUSDQuartile <- as.factor(cleaned_data$collateralAmountUSDQuartile)
cleaned_data$event <- as.factor(cleaned_data$event)

my_trainData3 <- cleaned_data[trainIndex3, ]
my_testData3 <- cleaned_data[-trainIndex3, ]
my_test_label3 <- my_testData3$event
my_testData3 <- my_testData3 %>%
  select(-c(event))

#Second method
library(ada)
library(caret)

# Train the AdaBoost model
ada_model <- ada(event ~ ., data = my_trainData3, iter = 50)

# Make predictions on the test set
preds_ada <- predict(ada_model, my_testData3)

# Ensure both predicted and actual labels are factors with the same levels
preds_ada <- factor(preds_ada, levels = c("yes", "no"))
my_test_label3 <- factor(my_test_label3, levels = c("yes", "no"))

# Evaluate model performance with a confusion matrix
confusion_ada <- confusionMatrix(preds_ada, my_test_label3)
print(confusion_ada)

#Sixth method for my data
library(e1071)

# Train Naive Bayes model
nb_model <- naiveBayes(event ~ ., data = my_trainData3)

# Convert predictions to binary class labels ("yes" or "no")
preds_nb <- predict(nb_model, my_testData3)

# Ensure both predicted and actual labels are factors with the same levels
preds_nb <- factor(preds_nb, levels = c("yes", "no"))
my_test_label3 <- factor(my_test_label3, levels = c("yes", "no"))

# Evaluate the model using confusion matrix
confusion_nb <- confusionMatrix(preds_nb, my_test_label3)
print(confusion_nb)

#The seventh method
library(e1071)

# Train SVM with cost-sensitive learning
svm_model <- svm(event ~ ., data = my_trainData3, kernel = "radial", class.weights = c("no" = 1, "yes" = 10))

# Predict and evaluate
preds_svm <- predict(svm_model, my_testData3)
# Ensure both predicted and actual labels are factors with the same levels
preds_svm <- factor(preds_svm, levels = c("yes", "no"))
my_test_label3 <- factor(my_test_label3, levels = c("yes", "no"))

# Evaluate model performance with confusion matrix
confusion_svm <- confusionMatrix(preds_svm, my_test_label3)
print(confusion_svm)

#Save as RDS
saveRDS(nb_model, file = "Borrow_Account_Liquidated_nb_model_RMST.rds")
saveRDS(preds_nb, file = "Borrow_Account_Liquidated_nb_model_predict_RMST.rds")
saveRDS(confusion_nb, file = "Borrow_Account_Liquidated_confusion_nb_RMST.rds")

# Saving AdaBoost model, predictions, and confusion matrix
saveRDS(ada_model, file = "Borrow_Account_Liquidated_ada_model_RMST.rds")
saveRDS(preds_ada, file = "Borrow_Account_Liquidated_ada_model_predict_RMST.rds")
saveRDS(confusion_ada, file = "Borrow_Account_Liquidated_confusion_ada_RMST.rds")

# Saving SVM model, predictions, and confusion matrix
saveRDS(svm_model, file = "Borrow_Account_Liquidated_svm_model_RMST.rds")
saveRDS(preds_svm, file = "Borrow_Account_Liquidated_svm_model_predict_RMST.rds")
saveRDS(confusion_svm, file = "Borrow_Account_Liquidated_confusion_svm_RMST.rds")
```

```{r}
# Load a single survival dataset with a specific index and outcome event:
indexEvent = "Repay/"
outcomeEvent = "Account Liquidated/"

my_survivalData = read_rds(paste0("/academics/MATP-4910-F24/DAR-DeFi-LTM-F24/Data/Survival_Data/", 
                               indexEvent, outcomeEvent, "survivalData.rds"))

# Rescale the timeDiff column to be in Days instead of Seconds
my_survivalData <- my_survivalData %>%
  mutate(timeDiff = timeDiff / 86400)

# Create a Surv object with our survival data:
my_survObj <- Surv(time = my_survivalData$timeDiff, event = my_survivalData$status)

# Fit a KM curve to this data:
my_survFit <- surv_fit(my_survObj ~ 1, data = my_survivalData)

my_survivalData <- my_survivalData %>%
  filter(!(timeDiff >= 9.90 & status == 0)) # filter out censored events with timeDiff less 
                                        # than one day

my_survivalDataForClassification <- my_survivalData %>%
  mutate(event = case_when(timeDiff <= 9.90 ~ "yes", # if the timeDiff is below our threshold, 
                                                  # set event="yes"
                           timeDiff > 9.90 ~ "no"))  # otherwise set event = "no"
# Plot the Kaplan--Meier curve:
my_kmPlot <- ggsurvplot(my_survFit,
             censor = FALSE,
             title = "How much percent of users is liquidated after borrowing money?",
             xlab = "Time (days)",
             break.x.by = 100,
             ylab = "Probability of Get liquidated",
             conf.int = TRUE)

my_kmPlot


# We need to be careful with the features we include. Some of the features present in 
# the data are not meant for performing tasks like classification, like the outcomeTime 
# which is NA for any censored events. Let's drop these features:

featuresToDrop = c("indexTime",   # This feature is primarily present for data exploration 
                                  # and investigation, but could interfere with a 
                                  # proper experiment
                   "outcomeTime", # This features is NA whenever an event is right-censored, 
                                  # which is often.
                   "id",          # This represents the transaction ID of the index event, 
                                  # which is useful for further investigation but not for 
                                  # an experiment
                   "Index Event", # For the sake of this exercise, the index event and outcome 
                                  # event should be the same for every row
                   "Outcome Event",
                   "timeDiff",    # event is based on timeDiff, which is what we're trying to 
                                  # predict for this classification problem
                   "deployment",  # this will be the same for all rows within a single 
                                  # survival dataset
                   "version",     # this will be the same for all rows within a single 
                                  # survival dataset
                   "indexID",     # this is only useful for looking up more details about a 
                                  # single transaction
                   "user",        # the user *could* be useful, but it's difficult to effectively 
                                  # use since its a factor with tons of levels
                   "status",      # this is sort of wrapped up in the "event" column we are trying
                                  # to predict
                   "quarter", 
                   
                   "liquidator"             
                   ) 

my_survivalDataForClassification <- my_survivalDataForClassification %>%
  select(-any_of(featuresToDrop)) %>% # Drop an entire list of named features
  drop_na()

# We also should convert relevant columns to factors:
my_survivalDataForClassification[] <- lapply(my_survivalDataForClassification, 
                                          function(x) if(is.character(x)) as.factor(x) else x)


# Compute the percentage of events in "yes" and "no"
pctPerEvent <- my_survivalDataForClassification %>%
  group_by(event) %>%
  dplyr::summarize(numPerEvent = n()) %>%
  mutate(total = sum(numPerEvent)) %>%
  mutate(percentage = numPerEvent / total) %>%
  dplyr::select(event, percentage)

kable(pctPerEvent) # View these percentages

#clean data
cleaned_data <- na.omit(my_survivalDataForClassification)
# Split data into training and test datasets
set.seed(123) # For reproducibility
# Ensure event column is a factor with exactly two levels
cleaned_data$event <- factor(cleaned_data$event, levels = c("yes", "no"))

# Now, try creating the partition again
set.seed(123)
trainIndex3 <- createDataPartition(cleaned_data$event, p = 0.8, list = FALSE)
#convert some int data into factors
cleaned_data$amountUSDQuartile <- as.factor(cleaned_data$amountUSDQuartile)
cleaned_data$principalAmountUSDQuartile <- as.factor(cleaned_data$principalAmountUSDQuartile)
cleaned_data$amountNativeQuartile <- as.factor(cleaned_data$amountNativeQuartile)
cleaned_data$collateralAmountUSDQuartile <- as.factor(cleaned_data$collateralAmountUSDQuartile)
cleaned_data$event <- as.factor(cleaned_data$event)

my_trainData3 <- cleaned_data[trainIndex3, ]
my_testData3 <- cleaned_data[-trainIndex3, ]
my_test_label3 <- my_testData3$event
my_testData3 <- my_testData3 %>%
  select(-c(event))

#Second method
library(ada)
library(caret)

# Train the AdaBoost model
ada_model <- ada(event ~ ., data = my_trainData3, iter = 50)

# Make predictions on the test set
preds_ada <- predict(ada_model, my_testData3)

# Ensure both predicted and actual labels are factors with the same levels
preds_ada <- factor(preds_ada, levels = c("yes", "no"))
my_test_label3 <- factor(my_test_label3, levels = c("yes", "no"))

# Evaluate model performance with a confusion matrix
confusion_ada <- confusionMatrix(preds_ada, my_test_label3)
print(confusion_ada)

#Sixth method for my data
library(e1071)

# Train Naive Bayes model
nb_model <- naiveBayes(event ~ ., data = my_trainData3)

# Convert predictions to binary class labels ("yes" or "no")
preds_nb <- predict(nb_model, my_testData3)

# Ensure both predicted and actual labels are factors with the same levels
preds_nb <- factor(preds_nb, levels = c("yes", "no"))
my_test_label3 <- factor(my_test_label3, levels = c("yes", "no"))

# Evaluate the model using confusion matrix
confusion_nb <- confusionMatrix(preds_nb, my_test_label3)
print(confusion_nb)

#The seventh method
library(e1071)

# Train SVM with cost-sensitive learning
svm_model <- svm(event ~ ., data = my_trainData3, kernel = "radial", class.weights = c("no" = 1, "yes" = 10))

# Predict and evaluate
preds_svm <- predict(svm_model, my_testData3)
# Ensure both predicted and actual labels are factors with the same levels
preds_svm <- factor(preds_svm, levels = c("yes", "no"))
my_test_label3 <- factor(my_test_label3, levels = c("yes", "no"))

# Evaluate model performance with confusion matrix
confusion_svm <- confusionMatrix(preds_svm, my_test_label3)
print(confusion_svm)

#Save as RDS
saveRDS(nb_model, file = "Repay_Account_Liquidated_nb_model_RMST.rds")
saveRDS(preds_nb, file = "Repay_Account_Liquidated_nb_model_predict_RMST.rds")
saveRDS(confusion_nb, file = "Repay_Account_Liquidated_confusion_nb_RMST.rds")

# Saving AdaBoost model, predictions, and confusion matrix
saveRDS(ada_model, file = "Repay_Account_Liquidated_ada_model_RMST.rds")
saveRDS(preds_ada, file = "Repay_Account_Liquidated_ada_model_predict_RMST.rds")
saveRDS(confusion_ada, file = "Repay_Account_Liquidated_confusion_ada_RMST.rds")

# Saving SVM model, predictions, and confusion matrix
saveRDS(svm_model, file = "Repay_Account_Liquidated_svm_model_RMST.rds")
saveRDS(preds_svm, file = "Repay_Account_Liquidated_svm_model_predict_RMST.rds")
saveRDS(confusion_svm, file = "Repay_Account_Liquidated_confusion_svm_RMST.rds")
```